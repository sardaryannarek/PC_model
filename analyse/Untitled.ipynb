{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0cabf5-5fe3-4b7c-a0ec-040aba2ad83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from core.PC_NET import PCNet\n",
    "from core.config import punct_label2id, cap_label2id, MODEL_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f75d170-e3e6-4a1a-870b-796545a0ba4f",
   "metadata": {},
   "outputs": [],
   "source": "train_dataset_path = \"../scripts/test.pt\""
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d92d391-5520-432f-b115-8a48ff5a0c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_batch(train_dataset_path, batch_size=10):\n",
    "    dataset = torch.load(train_dataset_path)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    sample_batch = next(iter(dataloader))\n",
    "    return sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c209a82-d93c-4a66-b39b-cec7bc098ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = load_sample_batch(train_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b4de99b-53e1-4d66-b53e-ee9b8211626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(train_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fff0256-25e1-474d-8c41-634ea753a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0458327d-d67d-4a94-af01-ed2a2e94f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PCNet(\n",
    "        model_name=MODEL_ID,\n",
    "        learning_rate=1e-4,  # Dummy value for testing\n",
    "        num_punct_classes=len(punct_label2id),\n",
    "        num_cap_classes=len(cap_label2id),\n",
    "        trainable_layers=2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f0212db-3bb2-45de-a0d5-17552d25a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = batch[\"input_ids\"]\n",
    "attention_mask = batch[\"attention_mask\"]\n",
    "punct_labels = batch[\"punct_labels\"]\n",
    "cap_labels = batch[\"cap_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0aaf2f1d-69b0-450d-83a0-08c70c532e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_logits, cap_logits = model(input_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "797e1d85-e494-483b-8fe4-736d60f1c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.compute_loss(punct_logits, cap_logits, punct_labels, cap_labels, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7461b11f-ee17-46fe-883d-482d969ca06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_logits = punct_logits.view(-1, 4)\n",
    "cap_logits = cap_logits.view(-1, 2)\n",
    "punct_labels = punct_labels.view(-1)\n",
    "cap_labels = cap_labels.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fb2f264-f313-4750-b2a8-f6b0ec298d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1280, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d3dd4f3-3281-44e4-9266-e9aae89ce2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_mask = attention_mask.view(-1) == 1  # Only consider valid tokens\n",
    "active_punct_labels = torch.where(active_mask, punct_labels, torch.tensor(-100))\n",
    "active_cap_labels = torch.where(active_mask, cap_labels, torch.tensor(-100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01180f81-76bd-4efa-a864-437cdfaf2ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1280])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_punct_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0366c33c-1134-4ac7-b4d7-b06c75ac90de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1280])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4fd3a4a-c8c5-47e2-a076-764f91976b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "punct_loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "cap_loss_fn = nn.CrossEntropyLoss(ignore_index=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38622244-c789-4376-90f2-c0359457e11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8110, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_loss_fn(punct_logits, active_punct_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9fb95af-4751-4773-88fd-5fa22238ea7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1280, 4])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "771e1170-0fb5-4d43-a581-3467ed1fb02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1280])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_punct_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8314961-f896-4a45-b5e5-7373864df5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fcbe73-233a-41d7-8ea5-fb5e38541f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cebd85d-63a1-4bcb-ad59-10e81905a79d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f81e7dc-63ca-4a1d-acec-1d7bf1fd68df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 128]), torch.Size([10, 128]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['punct_labels'].shape, batch['input_ids'].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02411de0-a3bd-425e-8d58-9ef1f75e7e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch['subword_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "705d317b-3ff2-42cd-81a3-871b3e647ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([50281, 10002,   261,  5681,   936, 12080,  1542,   262, 21808,   609,\n",
       "            85,   602, 34974,    74,  9903,   626,  9802,   266, 31984,   936,\n",
       "          3529,  1439, 15160,  2915,  5092,  1257,   290,  5924,   936, 35773,\n",
       "          3549,  2881, 12157,  5658, 12796,  6448,  1568,   262,   434,  1439,\n",
       "         24902,   262, 12756,  1257, 40199,  2858,  1059,   434, 50282, 50283,\n",
       "         50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283,\n",
       "         50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283,\n",
       "         50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283,\n",
       "         50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283,\n",
       "         50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283,\n",
       "         50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283,\n",
       "         50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283,\n",
       "         50283, 50283, 50283, 50283, 50283, 50283, 50283, 50283]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'punct_labels': tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            2,    0,    0,    0,    0,    0,    0,    0,    2,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            2,    0,    0,    0,    2,    0,    0,    0,    0,    0,    0,    0,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100]),\n",
       " 'cap_labels': tensor([-100,    1,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,\n",
       "            0,    1,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    1,    0,    0,    0,    1,    0,    0,    0,    0,    0,    0,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100]),\n",
       " 'subword_tokens': ['[CLS]',\n",
       "  'who',\n",
       "  'is',\n",
       "  'going',\n",
       "  'to',\n",
       "  'pay',\n",
       "  'for',\n",
       "  'it',\n",
       "  'those',\n",
       "  'are',\n",
       "  't',\n",
       "  'ough',\n",
       "  'questions',\n",
       "  'i',\n",
       "  'don',\n",
       "  \"'t\",\n",
       "  'have',\n",
       "  'an',\n",
       "  'answer',\n",
       "  'to',\n",
       "  'that',\n",
       "  'not',\n",
       "  'every',\n",
       "  'body',\n",
       "  'can',\n",
       "  'be',\n",
       "  'ent',\n",
       "  'itled',\n",
       "  'to',\n",
       "  'everything',\n",
       "  'sim',\n",
       "  'ply',\n",
       "  'because',\n",
       "  'you',\n",
       "  'were',\n",
       "  'born',\n",
       "  'here',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'not',\n",
       "  'possible',\n",
       "  'it',\n",
       "  'would',\n",
       "  'be',\n",
       "  'nice',\n",
       "  'but',\n",
       "  'let',\n",
       "  \"'s\",\n",
       "  '[SEP]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]',\n",
       "  '[PAD]']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb2b03-962a-40bd-bf61-067fcf25f906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ded3300-f443-4907-a1cc-4f44a1be504b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d787ac5-6bfa-47a8-ba0c-2e67339ea209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0739041-f3f4-4a8a-b8c7-24c03d426c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a15f3-d399-4491-af08-ed7941cd3a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c6cf5b4-a2ca-4b88-9895-ae9b2066b9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45208/2373801378.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(train_dataset_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running forward pass...\n",
      "Sequence output (min, max): -24.372268676757812, 45.467384338378906\n",
      "Punctuation logits (min, max): -1.7480071783065796, 1.8685516119003296\n",
      "Capitalization logits (min, max): -1.9483040571212769, 1.3317899703979492\n",
      "tensor(1.5256, device='cuda:0', grad_fn=<NllLossBackward0>) tensor(0.8925, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "_________________________\n",
      "Input IDs shape: torch.Size([10, 128])\n",
      "Attention mask shape: torch.Size([10, 128])\n",
      "Punctuation logits shape: torch.Size([10, 128, 4])\n",
      "Capitalization logits shape: torch.Size([10, 128, 2])\n",
      "Loss: 2.4180526733398438\n",
      "Punctuation logits (min, max): -1.7480071783065796, 1.8685516119003296\n",
      "Capitalization logits (min, max): -1.9483040571212769, 1.3317899703979492\n",
      "Punctuation labels: tensor([[-100,    0,    0,  ..., -100, -100, -100],\n",
      "        [-100,    0,    0,  ..., -100, -100, -100],\n",
      "        [-100,    0,    0,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [-100,    0,    0,  ..., -100, -100, -100],\n",
      "        [-100,    0,    0,  ..., -100, -100, -100],\n",
      "        [-100,    0,    0,  ..., -100, -100, -100]], device='cuda:0')\n",
      "Capitalization labels: tensor([[-100,    1,    0,  ..., -100, -100, -100],\n",
      "        [-100,    0,    0,  ..., -100, -100, -100],\n",
      "        [-100,    0,    0,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [-100,    0,    0,  ..., -100, -100, -100],\n",
      "        [-100,    0,    0,  ..., -100, -100, -100],\n",
      "        [-100,    0,    0,  ..., -100, -100, -100]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from core.PC_NET import PCNet\n",
    "from core.config import punct_label2id, cap_label2id, MODEL_ID\n",
    "\n",
    "# Load a sample batch from the training dataset\n",
    "def load_sample_batch(train_dataset_path, batch_size=10):\n",
    "    dataset = torch.load(train_dataset_path)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    sample_batch = next(iter(dataloader))\n",
    "    return sample_batch\n",
    "\n",
    "def sanity_check(train_dataset_path):\n",
    "    # Load a small sample batch\n",
    "    batch = load_sample_batch(train_dataset_path)\n",
    "\n",
    "    # Initialize model\n",
    "    model = PCNet(\n",
    "        model_name=MODEL_ID,\n",
    "        learning_rate=1e-4,  # Dummy value for testing\n",
    "        num_punct_classes=len(punct_label2id),\n",
    "        num_cap_classes=len(cap_label2id),\n",
    "        trainable_layers=2\n",
    "    )\n",
    "\n",
    "    # Move model to the device\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    model.to(device)\n",
    "    for name, param in model.named_parameters():\n",
    "        if torch.isnan(param).any():\n",
    "            print(f\"NaN detected in parameter: {name}\")\n",
    "    # Ensure all tensors in the batch are moved to the device\n",
    "    for key in batch:\n",
    "        if isinstance(batch[key], torch.Tensor):  # Only move tensors to the device\n",
    "            batch[key] = batch[key].to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    punct_labels = batch[\"punct_labels\"]\n",
    "    cap_labels = batch[\"cap_labels\"]\n",
    "\n",
    "    punct_logits, cap_logits = model(input_ids, attention_mask)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = model.compute_loss(punct_logits, cap_logits, punct_labels, cap_labels, attention_mask)\n",
    "    print(\"_\"* 25)\n",
    "    # Print results\n",
    "    print(f\"Input IDs shape: {input_ids.shape}\")\n",
    "    print(f\"Attention mask shape: {attention_mask.shape}\")\n",
    "    print(f\"Punctuation logits shape: {punct_logits.shape}\")\n",
    "    print(f\"Capitalization logits shape: {cap_logits.shape}\")\n",
    "    print(f\"Loss: {loss.item()}\")\n",
    "    print(f\"Punctuation logits (min, max): {punct_logits.min().item()}, {punct_logits.max().item()}\")\n",
    "    print(f\"Capitalization logits (min, max): {cap_logits.min().item()}, {cap_logits.max().item()}\")\n",
    "    print(f\"Punctuation labels: {punct_labels}\")\n",
    "    print(f\"Capitalization labels: {cap_labels}\")\n",
    "\n",
    "# Path to your training dataset\n",
    "train_dataset_path = \"../scripts/test.pt\"\n",
    "\n",
    "sanity_check(train_dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d8788-b962-4976-9e5a-6f0d434d247b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d11a6-545b-46b7-b7e3-95af54939313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd893585-9ccb-4eec-a006-41eb84222c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c70bc33-5a45-4b7b-bab6-bf70f17a1d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb404481-e50c-4a59-a52d-5a4129ec3653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6941cd0-4154-4cd6-9760-7835ab55d788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f934b55a-f374-4540-8e18-0abbee69bbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dbef83-d349-436a-9fc4-de5257ae483d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11402903-5990-4284-9b03-90f67c79b43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b78cac-b4c1-4d77-ab36-d0e327d50189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6381662-c2a6-473a-96e0-287a83472730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb574c26-afec-47da-9bfd-2af664643191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83bd1f9a-089d-4b50-852a-9e5040a77aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natali/Desktop/myenv2/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:167: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([1, 128])\n",
      "Attention mask shape: torch.Size([1, 128])\n",
      "Sequence output shape: torch.Size([1, 128, 768])\n",
      "Sequence output (min, max): -24.3582763671875, 46.94162368774414\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "MODEL_ID = \"answerdotai/ModernBERT-base\"\n",
    "\n",
    "def check_model_on_gpu():\n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "    model = AutoModel.from_pretrained(MODEL_ID)\n",
    "\n",
    "    # Move model to GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Sample input text\n",
    "    text = \"Hello, how are you doing today?\"\n",
    "\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", max_length=128, truncation=True)\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Input IDs shape: {input_ids.shape}\")\n",
    "    print(f\"Attention mask shape: {attention_mask.shape}\")\n",
    "    print(f\"Sequence output shape: {sequence_output.shape}\")\n",
    "    print(f\"Sequence output (min, max): {sequence_output.min().item()}, {sequence_output.max().item()}\")\n",
    "\n",
    "# Run the check\n",
    "check_model_on_gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4506b29-3a47-4dc4-9b19-0b6e3a14a9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cu121'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeb0cb2d-d91c-4b97-b373-1eee3836f9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca7e49-1dd1-4007-ab79-5d4b0640b751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
