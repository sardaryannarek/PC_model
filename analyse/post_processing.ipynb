{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-08T23:08:59.303627Z",
     "start_time": "2025-01-08T23:08:56.129545Z"
    }
   },
   "source": [
    "from torch.backends.cuda import allow_fp16_bf16_reduction_math_sdp\n",
    "\n",
    "from core.PC_NET import PCNet\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from core.dataset import collate_fn\n",
    "import yaml\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from core.config import punct_label2id\n",
    "\n",
    "model = PCNet.load_from_checkpoint('../logs_all/final_model_2_layer_Stable_adamw_lr_5e-5/PCNet_lr5e-5_layers2/best-checkpoint.ckpt')\n",
    "\n",
    "with open('../scripts/always_predictable.yml', 'r') as file:\n",
    "    yml_file = yaml.safe_load(file)\n",
    "\n",
    "always_capital = yml_file[\"always_capitalized_tokens\"]\n",
    "always_period = yml_file[\"always_period_abbreviations\"]\n",
    "\n",
    "dataset = torch.load('../data/pt_datasets/test.pt')\n",
    "dataloader = DataLoader(dataset, batch_size=512, shuffle=False, collate_fn=collate_fn)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20732/43335492.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load('../data/pt_datasets/test.pt')\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T23:07:55.892233Z",
     "start_time": "2025-01-08T23:07:55.887732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def post_processing(cap_label_pred, subword_tokens, punct_labels_pred, input_ids):\n",
    "    for batch_num in range(len(subword_tokens)):\n",
    "        for word_num in range(1, len(subword_tokens[batch_num] ) - 1):\n",
    "            if input_ids[batch_num][word_num] != input_ids[batch_num][word_num -1] and input_ids[batch_num][word_num] != input_ids[batch_num][word_num +1]:\n",
    "                if subword_tokens[batch_num][word_num] in always_capital:\n",
    "                    cap_label_pred[batch_num][word_num] = 1\n",
    "                if subword_tokens[batch_num][word_num] in always_period:\n",
    "                    punct_labels_pred[batch_num][word_num] = punct_label2id[\".\"]\n",
    "\n",
    "    return cap_label_pred, punct_labels_pred\n"
   ],
   "id": "51088d5078908d3a",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T23:08:20.694882Z",
     "start_time": "2025-01-08T23:07:56.601948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cap_preds = []\n",
    "cap_preds_processed = []\n",
    "cap_labels_all = []\n",
    "\n",
    "punct_labels_all = []\n",
    "punct_preds_ = []\n",
    "punct_preds_processed = []\n",
    "\n",
    "for batch in dataloader:\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    punct_labels = batch[\"punct_labels\"].to(device)\n",
    "    cap_labels = batch[\"cap_labels\"].to(device)\n",
    "    subword_tokens = batch[\"subword_tokens\"]\n",
    "\n",
    "    punct_logits, cap_logits = model(input_ids, attention_mask)\n",
    "    cap_labels_pred = torch.argmax(cap_logits, dim=-1)\n",
    "    punct_labels_pred = torch.argmax(punct_logits, dim=-1)\n",
    "    valid_mask = (attention_mask.view(-1) == 1) & (cap_labels.view(-1) != -100)\n",
    "    cap_preds.extend(cap_labels_pred.view(-1)[valid_mask].tolist())\n",
    "    cap_labels_all.extend(cap_labels.view(-1)[valid_mask].tolist())\n",
    "    cap_labels_pred_processed,punct_labels_processed = post_processing(cap_labels_pred, subword_tokens,punct_labels_pred, input_ids)\n",
    "    cap_preds_processed.extend(cap_labels_pred_processed.view(-1)[valid_mask].tolist())\n",
    "\n",
    "    punct_labels_all.extend(punct_labels.view(-1)[valid_mask].tolist())\n",
    "    punct_preds_.extend(punct_labels_pred.view(-1)[valid_mask].tolist())\n",
    "    punct_preds_processed.extend(punct_labels_processed.view(-1)[valid_mask].tolist())\n",
    "\n",
    "\n"
   ],
   "id": "f107d5d1ac803b94",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T23:08:24.236986Z",
     "start_time": "2025-01-08T23:08:23.989915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pre_processing_f1 = f1_score(cap_labels_all, cap_preds)\n",
    "post_processing_f1 = f1_score(cap_labels_all, cap_preds_processed)\n",
    "\n",
    "print(f\"Pre-processing F1: {pre_processing_f1}\")\n",
    "print(f\"Post-processing F1: {post_processing_f1}\")\n",
    "\n"
   ],
   "id": "3551e3b472b16998",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing F1: 0.7068517585016868\n",
      "Post-processing F1: 0.7110258132616831\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T23:09:06.200917Z",
     "start_time": "2025-01-08T23:09:05.833712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preprocessed_report = classification_report(y_true=punct_labels_all,\n",
    "                                            y_pred=punct_preds_,\n",
    "                                            target_names=list(punct_label2id.keys()))\n",
    "postprocessed_report = classification_report(y_true=punct_labels_all,\n",
    "                                            y_pred=punct_preds_processed,\n",
    "                                            target_names=list(punct_label2id.keys()))\n"
   ],
   "id": "e9c55f575f9ad783",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T23:09:32.581105Z",
     "start_time": "2025-01-08T23:09:32.578774Z"
    }
   },
   "cell_type": "code",
   "source": "print(preprocessed_report)\n",
   "id": "8c9d1ba0e0321f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.98      0.97    265028\n",
      "           ,       0.55      0.34      0.42     17004\n",
      "           .       0.57      0.59      0.58     14518\n",
      "           ?       0.53      0.27      0.36      1317\n",
      "\n",
      "    accuracy                           0.92    297867\n",
      "   macro avg       0.65      0.55      0.58    297867\n",
      "weighted avg       0.91      0.92      0.91    297867\n",
      "\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T23:09:33.290336Z",
     "start_time": "2025-01-08T23:09:33.287725Z"
    }
   },
   "cell_type": "code",
   "source": "print(postprocessed_report)",
   "id": "e1a9d02cae6e9289",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.98      0.97    265028\n",
      "           ,       0.55      0.34      0.42     17004\n",
      "           .       0.57      0.59      0.58     14518\n",
      "           ?       0.53      0.27      0.36      1317\n",
      "\n",
      "    accuracy                           0.92    297867\n",
      "   macro avg       0.65      0.55      0.58    297867\n",
      "weighted avg       0.91      0.92      0.91    297867\n",
      "\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T22:47:08.162801Z",
     "start_time": "2025-01-08T22:47:08.158611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def post_processing(cap_label_pred, subword_tokens, input_ids):\n",
    "    for batch_num in range(len(subword_tokens)):\n",
    "        for word_num in range(1, len(subword_tokens[batch_num] - 1)):\n",
    "            if input_ids[batch_num][word_num] != input_ids[batch_num][word_num -1] and input_ids[batch_num][word_num] != input_ids[batch_num][word_num +1]:\n",
    "                if subword_tokens[batch_num][word_num] in always_capital:\n",
    "                    cap_label_pred[batch_num][word_num] = 1\n",
    "\n",
    "    return cap_label_pred\n"
   ],
   "id": "768cb6f0b1e84495",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T23:03:19.377359Z",
     "start_time": "2025-01-08T23:03:19.374471Z"
    }
   },
   "cell_type": "code",
   "source": "punct_logits.shape",
   "id": "c28fadb8b2dc600f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([481, 63, 4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T23:03:30.473799Z",
     "start_time": "2025-01-08T23:03:30.469745Z"
    }
   },
   "cell_type": "code",
   "source": "torch.argmax(punct_logits, dim=-1).shape",
   "id": "f8c1cd2f5868e9ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([481, 63])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5ac9ff8d76cbb639"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ffb8214d2f52bea5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "da5aa75447748e24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "20ee5665afb402d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aa130aa01ba8f6f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fa6efd080dfab992"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c6a1753cd22ff6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c5be73b0d5cd589c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b55f780cd3b9187a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c2ca077fdf62db8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "527f7e0109b8e59f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c62547108179be53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "41f6f9d1c56b44c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "97498fe8c810a6d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8975b3b2c32e6e57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:12:38.207206Z",
     "start_time": "2025-01-09T00:12:38.203535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chunk(arr, window_size, stride):\n",
    "    chunks = [arr[i:i + window_size] for i in range(0, len(arr), stride)]\n",
    "    # return chunks if len(chunks[-1]) == window_size else chunks[:-1]\n",
    "    return chunks\n",
    "\n",
    "def mask_centrals(window_size, stride, include=None):\n",
    "    mask = [0] * window_size\n",
    "    mid = window_size // 2\n",
    "    start = mid - (stride // 2)\n",
    "    end = start + stride\n",
    "    if include == 'left':\n",
    "        mask[:end] = [1] * end\n",
    "    elif include == 'right':\n",
    "        mask[start:] = [1] * (window_size - start)\n",
    "    else:\n",
    "        mask[start:end] = [1] * stride\n",
    "    return mask"
   ],
   "id": "45505aa3127c241e",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:00:49.383261Z",
     "start_time": "2025-01-09T00:00:49.380568Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fa038884b40290f8",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:17:42.805016Z",
     "start_time": "2025-01-09T00:17:42.803128Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7f6129c05a120826",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:04:37.481341Z",
     "start_time": "2025-01-09T00:04:37.478643Z"
    }
   },
   "cell_type": "code",
   "source": "chunks = chunk(list(range(23)), 7, 3)",
   "id": "4f93545f1aa2c893",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:17:39.515437Z",
     "start_time": "2025-01-09T00:17:39.513806Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "413dbfc8d9ae98d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:14:17.794450Z",
     "start_time": "2025-01-09T00:14:17.791691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chunk(arr, window_size, stride):\n",
    "    chunks = [arr[i:i + window_size] for i in range(0, len(arr), stride)]\n",
    "    last = chunks.pop()\n",
    "    for it in last:\n",
    "        if it not in chunks[-1]:\n",
    "            chunks[-1].append(it)\n",
    "    return chunks"
   ],
   "id": "8dbc74f417324f9a",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "17274f6168dbc0cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c34ddfaa54fa14ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:14:21.288123Z",
     "start_time": "2025-01-09T00:14:21.284605Z"
    }
   },
   "cell_type": "code",
   "source": "print(chunk(list(range(23)), 7, 3))",
   "id": "d5410498462d34e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 4, 5, 6], [3, 4, 5, 6, 7, 8, 9], [6, 7, 8, 9, 10, 11, 12], [9, 10, 11, 12, 13, 14, 15], [12, 13, 14, 15, 16, 17, 18], [15, 16, 17, 18, 19, 20, 21], [18, 19, 20, 21, 22]]\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:17:53.121642Z",
     "start_time": "2025-01-09T00:17:53.118511Z"
    }
   },
   "cell_type": "code",
   "source": "mask_centrals",
   "id": "87183f9efbca72a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.mask_centrals(window_size, stride, include=None)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:18:25.948208Z",
     "start_time": "2025-01-09T00:18:25.944563Z"
    }
   },
   "cell_type": "code",
   "source": "mask_centrals(7, 3, include='right')",
   "id": "953075df6ceb386c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:23:58.421564Z",
     "start_time": "2025-01-09T00:23:58.417725Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d9957e17d702b9a1",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T01:11:09.527498Z",
     "start_time": "2025-01-09T01:11:09.521948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mask_centrals(window_size, stride, include=None):\n",
    "    mask = [0] * window_size\n",
    "    mid = window_size // 2\n",
    "    start = mid - (stride // 2)\n",
    "    end = start + stride\n",
    "    if include == 'left':\n",
    "        mask[:end] = [1] * end\n",
    "    elif include == 'right':\n",
    "        mask[start:] = [1] * (window_size - start)\n",
    "    else:\n",
    "        mask[start:end] = [1] * stride\n",
    "    return mask\n",
    "\n",
    "def make_chunk(arr, window_size, stride):\n",
    "    chunks = [arr[i:i + window_size] for i in range(0, len(arr), stride)]\n",
    "    last = chunks.pop()\n",
    "    for it in last:\n",
    "        if it not in chunks[-1]:\n",
    "            chunks[-1].append(it)\n",
    "    return chunks\n",
    "\n",
    "def create_pairs(len_seq, window_size,stride):\n",
    "    chunks = make_chunk(list(range(len_seq)), window_size, stride)\n",
    "    masks = [mask_centrals(window_size, stride,include='left')]\n",
    "    masks.extend([mask_centrals(window_size, stride) for _ in range(len(chunks) - 2)])\n",
    "\n",
    "\n",
    "    last = chunks.pop()\n",
    "    chunks[-1] = chunks[-1] + last\n",
    "    masks.append(mask_centrals(len(chunks[-1]), stride, include='right'))\n",
    "    return chunks, masks"
   ],
   "id": "9a955a76f9af04b5",
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T01:11:11.354558Z",
     "start_time": "2025-01-09T01:11:11.350346Z"
    }
   },
   "cell_type": "code",
   "source": "create_pairs(25, 9, 3)\n",
   "id": "b77fd97ded7512aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
       "  [3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       "  [6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
       "  [9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
       "  [12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       "  [15, 16, 17, 18, 19, 20, 21, 22, 23],\n",
       "  [18, 19, 20, 21, 22, 23, 24, 21, 22, 23, 24]],\n",
       " [[1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T01:02:40.972785Z",
     "start_time": "2025-01-09T01:02:40.968638Z"
    }
   },
   "cell_type": "code",
   "source": "mask_centrals(9,3, include='right')",
   "id": "ea4d46207815359d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:47:47.187484Z",
     "start_time": "2025-01-09T00:47:47.184691Z"
    }
   },
   "cell_type": "code",
   "source": "-i - diff",
   "id": "450ea43c9c768e0c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:41:48.621246Z",
     "start_time": "2025-01-09T00:41:48.617866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "l1 = [1,2,3,4,5,6,7,8,9,10]\n",
    "l1[-3:-1]"
   ],
   "id": "f1ab3bb2b3728389",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 9]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:23:01.622993Z",
     "start_time": "2025-01-09T00:23:01.620348Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5200c6814964aff5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:57:14.415580Z",
     "start_time": "2025-01-09T00:57:14.410923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_chunks(data, window_size, stride):\n",
    "    \"\"\"\n",
    "    Breaks `data` (a list or array) into overlapping (or potentially partially overlapping) chunks.\n",
    "    The step between consecutive chunks is given by `stride`.\n",
    "\n",
    "    Example:\n",
    "        data = [0, 1, 2, 3, 4, 5, 6]\n",
    "        window_size = 3\n",
    "        stride = 2\n",
    "        -> chunks = [\n",
    "             [0, 1, 2],\n",
    "             [2, 3, 4],\n",
    "             [4, 5, 6]    # Last chunk\n",
    "           ]\n",
    "    Then the last chunk is merged with the penultimate chunk if there are\n",
    "    distinct elements that are not in the penultimate chunk.\n",
    "    \"\"\"\n",
    "    if stride <= 0:\n",
    "        raise ValueError(\"`stride` must be a positive integer.\")\n",
    "    if window_size <= 0:\n",
    "        raise ValueError(\"`window_size` must be a positive integer.\")\n",
    "\n",
    "    # Create list of chunks\n",
    "    chunks = [data[i : i + window_size] for i in range(0, len(data), stride)]\n",
    "\n",
    "    # If there's more than one chunk, merge the last chunk into the penultimate\n",
    "    # so that duplicates are not repeated.\n",
    "    if len(chunks) > 1:\n",
    "        last_chunk = chunks.pop()\n",
    "        for item in last_chunk:\n",
    "            if item not in chunks[-1]:\n",
    "                chunks[-1].append(item)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def create_pairs(sequence_length, window_size, stride):\n",
    "    \"\"\"\n",
    "    Returns masks and chunk indices for a sequence of length `sequence_length`.\n",
    "    Internally uses `make_chunks` to chunk the range [0, 1, ..., sequence_length - 1].\n",
    "    It then constructs masks using `mask_centrals`, and handles a short last chunk case\n",
    "    by taking items from the penultimate chunk.\n",
    "\n",
    "    Parameters:\n",
    "        sequence_length (int) : The length of the sequence (e.g. len_seq).\n",
    "        window_size (int)     : Size of each window or chunk.\n",
    "        stride (int)          : Step size between consecutive chunks.\n",
    "\n",
    "    Returns:\n",
    "        masks (list)  : A list of masks created by `mask_centrals`.\n",
    "        chunks (list) : A list of chunked indices.\n",
    "    \"\"\"\n",
    "    # Create chunks from 0..sequence_length-1\n",
    "    chunks = make_chunks(list(range(sequence_length)), window_size, stride)\n",
    "\n",
    "    # Build masks: first mask with include='left', then middle masks, etc.\n",
    "    # (Assuming `mask_centrals` is your own function available in the namespace.)\n",
    "    masks = [mask_centrals(window_size, stride, include='left')]\n",
    "    masks.extend([mask_centrals(window_size, stride) for _ in range(len(chunks) - 2)])\n",
    "\n",
    "    # If the last chunk is smaller than window_size, attempt to prepend\n",
    "    # missing items from the penultimate chunk.\n",
    "    if len(chunks) >= 2 and len(chunks[-1]) < window_size:\n",
    "        i = 1\n",
    "        while chunks[-2][-i] in chunks[-1]:\n",
    "            i += 1\n",
    "        diff = window_size - len(chunks[-1])\n",
    "        # Merge the needed slice from the penultimate chunk with the last chunk\n",
    "        chunks[-1] = chunks[-2][-i : -i + diff] + chunks[-1]\n",
    "\n",
    "    return masks, chunks\n"
   ],
   "id": "a86c00805d63ba79",
   "outputs": [],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:57:14.942178Z",
     "start_time": "2025-01-09T00:57:14.938230Z"
    }
   },
   "cell_type": "code",
   "source": "create_pairs(29, 10, 3)",
   "id": "e41d4ab78101a525",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 1, 1, 1, 0, 0, 0]],\n",
       " [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "  [3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
       "  [6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
       "  [9, 10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
       "  [12, 13, 14, 15, 16, 17, 18, 19, 20, 21],\n",
       "  [15, 16, 17, 18, 19, 20, 21, 22, 23, 24],\n",
       "  [18, 19, 20, 21, 22, 23, 24, 25, 26, 27],\n",
       "  [21, 22, 23, 24, 25, 26, 27, 28],\n",
       "  [23, 24, 25, 26, 27, 24, 25, 26, 27, 28]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T00:53:57.973264Z",
     "start_time": "2025-01-09T00:53:57.967918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_chunks(data, window_size, stride):\n",
    "    \"\"\"\n",
    "    Create chunks of length `window_size`, stepping by `stride`.\n",
    "    If the last chunk is smaller than `window_size`, it will be \"topped up\"\n",
    "    by elements from the penultimate chunk (without creating duplicates).\n",
    "\n",
    "    Example:\n",
    "        data = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "        window_size = 5\n",
    "        stride = 3\n",
    "\n",
    "        # Normal chunking\n",
    "        #   [10, 11, 12, 13, 14]\n",
    "        #   [13, 14, 15, 16, 17]\n",
    "        #   [16, 17, 18, 19, 20]  <-- last chunk is already length 5\n",
    "        # If last chunk was smaller, we fill it up from the penultimate chunk.\n",
    "    \"\"\"\n",
    "    if window_size <= 0:\n",
    "        raise ValueError(\"`window_size` must be a positive integer.\")\n",
    "    if stride <= 0:\n",
    "        raise ValueError(\"`stride` must be a positive integer.\")\n",
    "\n",
    "    # Make the initial chunks\n",
    "    chunks = [data[i : i + window_size] for i in range(0, len(data), stride)]\n",
    "\n",
    "    # If there's only one chunk or none, nothing more to do\n",
    "    if len(chunks) < 2:\n",
    "        return chunks\n",
    "\n",
    "    # If the last chunk is too short, top it up from the penultimate chunk\n",
    "    if len(chunks[-1]) < window_size:\n",
    "        needed = window_size - len(chunks[-1])\n",
    "        # We'll take items from the end of the penultimate chunk\n",
    "        penult_chunk = chunks[-2]\n",
    "\n",
    "        # Gather items from the end of penult_chunk (in reverse),\n",
    "        # skipping items already in the last chunk, until we have 'needed' items.\n",
    "        reversed_fill = []\n",
    "        for item in reversed(penult_chunk):\n",
    "            # Only add if not already in the last chunk\n",
    "            if item not in chunks[-1]:\n",
    "                reversed_fill.append(item)\n",
    "            # Stop if we have enough\n",
    "            if len(reversed_fill) == needed:\n",
    "                break\n",
    "\n",
    "        # Reverse them to restore the original order\n",
    "        reversed_fill.reverse()\n",
    "\n",
    "        # Prepend to the last chunk\n",
    "        chunks[-1] = reversed_fill + chunks[-1]\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def create_pairs(sequence_length, window_size, stride):\n",
    "    \"\"\"\n",
    "    Demonstration wrapper that shows how you might call `make_chunks`\n",
    "    and do additional operations (like building masks).\n",
    "\n",
    "    Example usage:\n",
    "        masks, chunks = create_pairs(25, 5, 3)\n",
    "    \"\"\"\n",
    "    # Chunk up the sequence of indices\n",
    "    chunks = make_chunks(list(range(sequence_length)), window_size, stride)\n",
    "\n",
    "    # Build your masks in whatever way `mask_centrals` is defined.\n",
    "    # Example placeholders:\n",
    "    masks = []\n",
    "    if hasattr(globals(), 'mask_centrals'):\n",
    "        # First mask with include='left' if thatâ€™s how you like it\n",
    "        masks.append(mask_centrals(window_size, stride, include='left'))\n",
    "        # For each extra chunk (beyond the first and last), do standard masking\n",
    "        num_extra = max(0, len(chunks) - 2)\n",
    "        masks.extend(mask_centrals(window_size, stride) for _ in range(num_extra))\n",
    "\n",
    "    return masks, chunks"
   ],
   "id": "b580138b8999421f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks:\n",
      "[15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "[17, 18, 19, 20, 21, 22, 23]\n",
      "[19, 20, 21, 22, 23]\n",
      "[21, 22, 23]\n",
      "[21, 22, 23]\n"
     ]
    }
   ],
   "execution_count": 152
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "af6f70130b5018a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
